# 기초 개념

프로젝트의 배경과 검증 방법론의 기본 개념을 다룹니다.

---

## Q0: 왜 "from scratch" vs "fine-tuning" 논란이 발생하나요?

**질문 시각**: 2026-01-05

**답변**:

한국 정부의 국가 AI 파운데이션 모델 프로젝트는 "from scratch 학습"을 필수 요건으로 규정하고 있습니다. 여기서 from scratch란 무작위로 초기화된 weight에서 시작하여 전체 학습을 수행하는 것을 의미하며, 기존 모델의 pre-trained weight를 가져와 추가 학습하는 fine-tuning과는 근본적으로 다릅니다.

이 구분이 중요한 첫 번째 이유는 AI 주권 문제입니다. 기존 모델의 weight를 사용하면 해당 모델의 라이선스와 제약에 종속되기 때문에, 국가 전략 기술로서 독자적인 기술력을 보유하려면 from scratch 학습이 필수적입니다. 향후 모델을 수정하거나 확장할 때의 자유도 역시 from scratch일 때만 확보됩니다.

두 번째 이유는 국민 세금 사용과 관련됩니다. 국가 프로젝트는 정부 예산으로 진행되는데, fine-tuning은 from scratch 대비 훨씬 적은 비용으로 가능합니다. 학습 토큰 수로 비교하면 from scratch는 수조에서 수십조 토큰이 필요하지만, fine-tuning은 수십억에서 수백억 토큰이면 충분합니다. GPU 시간도 from scratch는 수만에서 수십만 GPU-hours가 드는 반면, fine-tuning은 수백에서 수천 GPU-hours로 가능합니다. 비용으로 환산하면 from scratch는 수백억에서 수천억 원이 소요되지만, fine-tuning은 수억에서 수십억 원 수준입니다. 따라서 from scratch 비용을 받고 fine-tuning만 했다면 이는 예산 낭비 또는 사기 논란으로 이어질 수 있습니다.

세 번째 이유는 신뢰도와 평판입니다. "from scratch"라고 주장했는데 실제로는 fine-tuning이었다면 심각한 신뢰 손상이 발생합니다. 이는 국제 AI 커뮤니티에서 한국 AI 기술력의 평판에 영향을 미치고, 후속 프로젝트 및 투자 유치에도 부정적 영향을 줍니다.

---

## Q1: LLM이 "from scratch"로 학습되었는지 어떻게 검증할 수 있나요?

**질문 시각**: 2026-01-04

**답변**:

LLM이 from scratch로 학습되었는지 검증하는 방법은 여러 가지가 있으며, 각각 장단점이 있습니다.

가장 접근성이 높은 방법은 Tokenizer 분석입니다. Tokenizer는 재학습 비용이 높아서 fine-tuning 시에는 거의 재사용됩니다. 따라서 vocabulary의 95% 이상이 기존 모델과 동일하면 fine-tuning 가능성이 높습니다. `tokenizer.get_vocab()`으로 vocabulary를 추출하여 비교할 수 있습니다.

Weight 분석도 효과적인 방법입니다. Fine-tuned 모델은 초기 레이어에서 base model과 90% 이상의 cosine similarity를 유지하는 경향이 있습니다. SHA-256 해시로 weight tensor를 비교하거나, PCA 분석으로 weight 분포를 시각화할 수 있습니다. From scratch 모델은 PCA에서 orthogonal한 분포를 보입니다.

Architecture 비교는 `model.config`로 hyperparameter를 확인하는 방식입니다. 동일한 config는 fine-tuning의 강력한 증거이며, 고유한 구성요소가 있다면 from scratch 증거가 됩니다. 예를 들어 특이한 RoPE scaling 설정 같은 것이 그렇습니다.

행동 테스트는 Knowledge cutoff 날짜를 확인하거나, Safety alignment와 refusal pattern이 base model과 동일한지 살펴보는 방식입니다. 이런 패턴이 유사하면 fine-tuning 가능성이 있습니다.

Compute 추정도 간접적인 증거가 됩니다. From scratch는 fine-tuning 대비 10-100배 더 많은 compute가 필요합니다. 예를 들어 19.7T tokens 학습은 massive compute를 요구하므로, from scratch 주장과 일관성이 있습니다.

신뢰도 측면에서 보면, Training Logs가 가장 높은 신뢰도를 가지지만 접근성이 낮습니다. Tokenizer 분석은 신뢰도와 접근성이 모두 높아서 첫 번째 검증 수단으로 적합합니다.

---

<!-- SECTION_MARKER: 새로운 기초개념 Q&A는 이 마커 위에 추가됩니다 -->
